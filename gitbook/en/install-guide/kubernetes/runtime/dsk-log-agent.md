# dsk-log-agent

## Installing DataSaker Log agent in Kubernetes environment

A `Log agent` is an agent that collects, processes and transmits log data generated by systems or applications in near real time in various environments. It can be used to centrally manage and analyze log data generated by multiple servers through `Log agent`. As a result, users can quickly detect and respond to problems occurring in the system or applications. In addition, log data can be analyzed and used for various purposes such as security, performance, and business analysis. We tailor agent settings to your needs to deliver optimal results.

## Did you run the DataSaker predecessor?

If the preceding task of `DataSaker` has not been carried out in the current Kubernetes environment, please proceed with the preceding task of `DataSaker` first. [DataSaker predecessors] (README.md)

## Install Log agent

By default, the `Log agent` is deployed as a daemonset by default in a Kubernetes environment. Thus, a `Log agent` is installed on all nodes. If you want to install `Log agent` only on a specific node, additionally set affinity or nodeSelector for that node.

### 1. Log agent setting value registration

The meaning and default setting values ​​of `Log agent` are as follows. Different users have different requirements for agent setup. Therefore, the agent settings must be adjusted to suit the user's settings. Tune your agent settings for optimal results. Add or edit these values ​​in "\~/datasaker/config.yaml".

Following is a description of each setting item in the log agent configuration file.
```yaml
logAgent:
  logs:
    - service:
      tag: []
      keyword: []
      multiline:
        format:
        pattern: []
      masking:
        - pattern:
          replace:
      collect:
        type:
        category:
        address:
        file:
          paths: []
          exclude_paths: []
        kubernetes:
          - namespace:
            pod:
            container:
```
| **Settings** | **Description** | **Default** |
| ----------------------------------- | --------------------------------------------------------------------------------------- |:-----------------:|
| **logs** | Log collection target information | |
| `service` | Service name of the log collection destination | `default` |
| `tag` | Tag of log collection target | |
| `keyword` | Log Collection Keywords (collects only logs containing keywords) | |
| **multiline** | Multi-line log collection settings | |
| `format` | multi-line log format (eg go, java, python) | |
| `pattern` | Multi-line log pattern (e.g. ^\d{4}-\d{2}-\d{2}) - User custom regex pattern can be used | |
| **masking** | Sensitive information log masking settings | |
| `pattern` | Log pattern to mask (e.g. ^\d{4}-\d{2}-\d{2}) - user custom regex pattern available | |
| `replace` | The string where the masking pattern is to be replaced (eg ******) | |
| **collect** | Log Collection Target Settings | |
| `type` | log collection method (write one value among `file`, `driver`, `kubernetes`) | `file` |
| `category` | service classification (write a value of one of `app`, `database`, `syslog`, `etc`) | `etc` |
| `address` | Database host and port information (set when the service category is database) | |
| **file** | If the log collection method is file, set | |
| `paths` | Log collection destination path (e.g. /var/log/sample/*.log) | `/var/log/*.log` |
| `exclude_paths` | Log collection exclusion target path | |
| **kubernetes** | If the log collection method is kubernetes, Settings | |
| `namespace` | Log Collection Target Namespace | `*` |
| `pod` | Pod name for log collection | `*` |
| `container` | Log collection target container name | `*` |

In a Kubernetes environment, log agents can collect logs in two ways.

* **kubernetes** : Collects logs through the information of the workload to collect logs. Set the namespace, pod name, and container name of the workload to collect. (If you deploy your log agent as a Daemonset, use that method.)
* **file** : Collect the log file directly. Mount the logs to be collected directly on the log agent and set the relative path to the log file to be collected. (If you deploy the log agent as a sidecar pattern, use that method.)

For example, if you're collecting logs via Kubernetes workload information, you could write a configuration file like this:If you have a workload configured with the following manifest file:

 ```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selectors:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      -name: nginx
        image: nginx:1.14.2
        ports:
        -containerPort: 80
 ```

You can write your log agent YAML configuration file like this:
```shell
cat << EOF >> ~/datasaker/config.yaml
logAgent:
  enabled: true
  logs:
    - collect:
        type: kubernetes
        kubernetes:
          - namespace: default
            pod: nginx-deployment
            container: nginx
EOF
```
If you want to collect all log files for a workload with a specific namespace/pod/container name, you can collect logs for all workloads with that keyword by writing only a common keyword.

If you want to collect logs from all containers for pods with the name nginx in all namespaces, you can write a configuration file like this:
(Caution: If no value is written in namespace/pod/container, logs of all containers are collected for all namespace/pod/containers.)
```shell
cat << EOF >> ~/datasaker/config.yaml
logAgent:
  enabled: true
  logs:
    - collect:
        type: kubernetes
        kubernetes:
          - pod: nginx
EOF
```
If you collect log files yourself, you can write a configuration file like this:
```shell
cat << EOF >> ~/datasaker/config.yaml
logAgent:
  enabled: true
  logs:
    - collect:
        type: file
        file:
          paths:
           - /var/log/containers/nginx-deployment*default*nginx*.log
EOF
```
### 2. Log agent installation
```shell
helm upgrade datasaker datasaker/agent-helm -n datasaker -f ~/datasaker/config.yaml
```
## Log agent log collection setup

`Log agent` supports multi-line log collection and log masking settings via the agent configuration YAML file.

### 1. Multi-line log collection settings

Log agent configuration YAML files support multi-line log collection settings in two ways.

* **format** : Sets the multi-line log format. Currently, three formats are supported: `go`, `java` and `python`.
* **pattern** : Sets the multi-line log pattern. You can use your custom regular expression pattern.
```yaml
logs:
  - multiline:
      format:
      pattern: []
```
For example, if you have a multi-line log like this:
```shell
Dec 14 06:41:08 Exception in thread "main" java.lang.RuntimeException: Something has gone wrong, aborting!
    at com.myproject.module.MyProject.badMethod(MyProject.java:22)
    at com.myproject.module.MyProject.oneMoreMethod(MyProject.java:18)
    at com.myproject.module.MyProject.anotherMethod(MyProject.java:14)
    at com.myproject.module.MyProject.someMethod(MyProject.java:10)
    at com.myproject.module.MyProject.main(MyProject.java:6)
```
You can collect multi-line logs as follows through the `format` setting.
```yaml
logs:
  - multiline:
      format: 'java'
```
**\[Caution]** The method of collecting multi-line logs through `format` cannot collect multi-line logs of all patterns. For accurate multi-line log collection, it is recommended to configure multi-line log collection through `pattern`.

In the case of collecting multi-line logs through `pattern`, which is another method, it can be written as follows.
```yaml
logs:
  - multiline:
      pattern: 
        - '^\w*\s\d{1,2}\s\d{1,2}\:\d{1,2}\:\d{1,2}'
```
If you create a pattern at the beginning of a log for multi-line logs, multi-line logs are collected based on logs starting with the pattern.

**\[Caution]** The log agent determines that the second line in multi-line log collection starts with a blank space.

### 2. Set sensitive information log masking

Log agent configuration YAML files support sensitive log masking settings.

* **pattern** : Sets the log pattern to be masked. You can use your custom regular expression pattern.
* **replace** : Sets the string to be replaced with the masking pattern.
```yaml
logs:
  - masking:
      - pattern:
        replace:
```
For example, if you have the following log,
```shell
2023-08-18 06:35:38.993 GMT [739243] LOG:  statement:
            SELECT * 
            FROM address 
            WHERE id = '1234567890';
```
If you want to mask the query statement following `statement:` in the log with the string `PRIVATE_QUERY`, you can mask it by writing a regular expression pattern in `pattern` as follows.
```yaml
logs:
  - masking:
      - pattern: 'statement: .*'
        replace: 'statement: PRIVATE_QUERY'
```
